#!/usr/bin/env python3
"""
ê³„ì¸µì  ì¡°-í•­-í˜¸ êµ¬ì¡°ë¡œ PDF ë³´í—˜ì•½ê´€ Ingestion

- Article (ì¡°)
- Paragraph (í•­)
- Item (í˜¸)
- ê° ë ˆë²¨ë³„ ì„ë² ë”©
- ì¡°í•­ ê°„ ìƒí˜¸ ì°¸ì¡° ê´€ê³„
"""
import sys
from pathlib import Path

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

import argparse
from loguru import logger
from openai import OpenAI
from neo4j import GraphDatabase

from src.config.settings import settings
from src.parsers.pdf_parser import PolicyPDFParser
from src.parsers.clause_extractor import ClauseExtractor


def main():
    parser = argparse.ArgumentParser(description="Ingest PDF with hierarchical structure (ì¡°-í•­-í˜¸)")
    parser.add_argument("--pdf", type=str, required=True, help="Path to PDF file")
    parser.add_argument("--product-code", type=str, required=True, help="Product code")
    parser.add_argument("--product-name", type=str, required=True, help="Product name")
    parser.add_argument("--version-id", type=str, required=True, help="Version ID")
    parser.add_argument("--max-clauses", type=int, default=None, help="Max clauses to process")
    
    args = parser.parse_args()
    
    pdf_file = Path(args.pdf)
    product_code = args.product_code
    product_name = args.product_name
    version_id = args.version_id
    max_clauses = args.max_clauses
    
    if not pdf_file.exists():
        logger.error(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_file}")
        return
    
    logger.info("="*80)
    logger.info("ğŸ“¦ ê³„ì¸µì  PDF Ingestion ì‹œì‘ (ì¡°-í•­-í˜¸)")
    logger.info("="*80)
    logger.info(f"PDF: {pdf_file.name}")
    logger.info(f"Product: {product_name} ({product_code})")
    logger.info(f"Version: {version_id}")
    if max_clauses:
        logger.info(f"Max Clauses: {max_clauses}")
    logger.info("="*80)
    
    # Initialize clients
    openai_client = OpenAI(api_key=settings.openai_api_key)
    driver = GraphDatabase.driver(
        settings.neo4j_uri,
        auth=(settings.neo4j_username, settings.neo4j_password)
    )
    
    stats = {
        'pdf_file': pdf_file.name,
        'pages': 0,
        'total_clauses': 0,
        'processed_clauses': 0,
        'paragraphs': 0,
        'items': 0,
        'cross_references': 0,
        'embeddings': 0,
        'nodes_created': 0
    }
    
    try:
        # Step 1: Parse PDF
        logger.info("\n[Step 1] PDF íŒŒì‹± ì¤‘...")
        pdf_parser = PolicyPDFParser(str(pdf_file))
        pages = pdf_parser.extract_text_by_page()
        text = pdf_parser.extract_full_text()
        stats['pages'] = len(pages)
        logger.info(f"  âœ… {stats['pages']}í˜ì´ì§€ ì¶”ì¶œ")
        
        # Step 2: Extract clauses
        logger.info("\n[Step 2] ì¡°í•­ ì¶”ì¶œ ì¤‘...")
        extractor = ClauseExtractor()
        all_clauses = extractor.extract_clauses(text)
        stats['total_clauses'] = len(all_clauses)
        
        # Limit clauses if needed
        clauses = all_clauses[:max_clauses] if max_clauses else all_clauses
        stats['processed_clauses'] = len(clauses)
        logger.info(f"  âœ… ì²˜ë¦¬í•  ì¡°í•­: {stats['processed_clauses']}ê°œ")
        
        # Step 3: Extract paragraphs and items
        logger.info("\n[Step 3] í•­(é …)ê³¼ í˜¸(è™Ÿ) ì¶”ì¶œ ì¤‘...")
        all_paragraphs = []
        all_items = []
        
        for clause in clauses:
            paragraphs, items = extractor.extract_paragraphs_and_items(clause)
            all_paragraphs.extend(paragraphs)
            all_items.extend(items)
        
        stats['paragraphs'] = len(all_paragraphs)
        stats['items'] = len(all_items)
        logger.info(f"  âœ… í•­: {stats['paragraphs']}ê°œ, í˜¸: {stats['items']}ê°œ")
        
        # Step 4: Find cross-references (from Paragraphs and Items)
        logger.info("\n[Step 4] í•­/í˜¸ ê°„ ìƒí˜¸ ì°¸ì¡° íƒìƒ‰ ì¤‘...")
        all_references = []
        
        # Find references from Paragraphs
        for paragraph in all_paragraphs:
            refs = extractor.find_cross_references(paragraph.text)
            for ref in refs:
                all_references.append({
                    'from_id': paragraph.paragraph_id,
                    'from_type': 'paragraph',
                    'to_id': ref['to'],
                    'to_type': ref['type']
                })
        
        # Find references from Items
        for item in all_items:
            refs = extractor.find_cross_references(item.text)
            for ref in refs:
                all_references.append({
                    'from_id': item.item_id,
                    'from_type': 'item',
                    'to_id': ref['to'],
                    'to_type': ref['type']
                })
        
        stats['cross_references'] = len(all_references)
        logger.info(f"  âœ… {stats['cross_references']}ê°œ ìƒí˜¸ ì°¸ì¡° ë°œê²¬")
        
        # Step 5: Generate embeddings
        logger.info("\n[Step 5] ì„ë² ë”© ìƒì„± ì¤‘...")
        
        # Clause embeddings
        logger.info(f"  [5.1] ì¡°(æ¢) ì„ë² ë”© ìƒì„± ì¤‘... ({len(clauses)}ê°œ)")
        for i, clause in enumerate(clauses, 1):
            try:
                response = openai_client.embeddings.create(
                    model=settings.embedding_model,
                    input=clause.full_text
                )
                clause.embedding = response.data[0].embedding
                stats['embeddings'] += 1
            except Exception as e:
                logger.warning(f"  âœ— ì¡°í•­ {clause.clause_id} ì„ë² ë”© ì‹¤íŒ¨: {e}")
        
        logger.info(f"  âœ… {len(clauses)}ê°œ ì¡°í•­ ì„ë² ë”© ì™„ë£Œ")
        
        # Paragraph embeddings
        logger.info(f"  [5.2] í•­(é …) ì„ë² ë”© ìƒì„± ì¤‘... ({len(all_paragraphs)}ê°œ)")
        for i, paragraph in enumerate(all_paragraphs, 1):
            try:
                response = openai_client.embeddings.create(
                    model=settings.embedding_model,
                    input=paragraph.text
                )
                paragraph.embedding = response.data[0].embedding
                stats['embeddings'] += 1
            except Exception as e:
                logger.warning(f"  âœ— í•­ {paragraph.paragraph_id} ì„ë² ë”© ì‹¤íŒ¨: {e}")
        
        logger.info(f"  âœ… {len(all_paragraphs)}ê°œ í•­ ì„ë² ë”© ì™„ë£Œ")
        
        # Item embeddings
        logger.info(f"  [5.3] í˜¸(è™Ÿ) ì„ë² ë”© ìƒì„± ì¤‘... ({len(all_items)}ê°œ)")
        for i, item in enumerate(all_items, 1):
            try:
                response = openai_client.embeddings.create(
                    model=settings.embedding_model,
                    input=item.text
                )
                item.embedding = response.data[0].embedding
                stats['embeddings'] += 1
            except Exception as e:
                logger.warning(f"  âœ— í˜¸ {item.item_id} ì„ë² ë”© ì‹¤íŒ¨: {e}")
        
        logger.info(f"  âœ… {len(all_items)}ê°œ í˜¸ ì„ë² ë”© ì™„ë£Œ")
        logger.info(f"  âœ… ì´ {stats['embeddings']}ê°œ ì„ë² ë”© ìƒì„± ì™„ë£Œ")
        
        # Step 6: Load to Neo4j
        logger.info("\n[Step 6] Neo4jì— ë¡œë”© ì¤‘...")
        
        with driver.session() as session:
            # Create product
            logger.info(f"  ìƒí’ˆ ìƒì„±: {product_name}")
            session.run("""
                MERGE (prod:InsuranceProduct {code: $code})
                SET prod.name = $name,
                    prod.kind = 'personal_injury',
                    prod.lineOfBusiness = 'personal'
                """,
                code=product_code,
                name=product_name
            )
            
            # Create version
            logger.info(f"  ë²„ì „ ìƒì„±: {version_id}")
            session.run("""
                MATCH (prod:InsuranceProduct {code: $product_code})
                MERGE (ver:PolicyVersion {versionId: $version_id})
                SET ver.effectiveFrom = date(),
                    ver.documentUrl = $pdf_path
                MERGE (prod)-[:HAS_POLICY_VERSION]->(ver)
                """,
                product_code=product_code,
                version_id=version_id,
                pdf_path=str(pdf_file)
            )
            
            # Create articles (ì¡°)
            logger.info(f"  ì¡°(æ¢) ë¡œë”©: {len(clauses)}ê°œ")
            for clause in clauses:
                session.run("""
                    MATCH (ver:PolicyVersion {versionId: $version_id})
                    MERGE (a:Article {articleId: $article_id})
                    SET a.number = $number,
                        a.title = $title,
                        a.text = $text,
                        a.clauseType = $clause_type,
                        a.embedding = $embedding
                    MERGE (ver)-[:HAS_ARTICLE]->(a)
                    """,
                    version_id=version_id,
                    article_id=clause.clause_id,
                    number=clause.article_number,
                    title=clause.title,
                    text=clause.full_text,
                    clause_type=clause.clause_type or 'General',
                    embedding=clause.embedding if hasattr(clause, 'embedding') else None
                )
                stats['nodes_created'] += 1
            
            logger.info(f"  âœ… {len(clauses)}ê°œ ì¡° ë¡œë”© ì™„ë£Œ")
            
            # Create paragraphs (í•­)
            logger.info(f"  í•­(é …) ë¡œë”©: {len(all_paragraphs)}ê°œ")
            for paragraph in all_paragraphs:
                session.run("""
                    MATCH (a:Article {articleId: $parent_article})
                    MERGE (p:Paragraph {paragraphId: $paragraph_id})
                    SET p.number = $number,
                        p.text = $text,
                        p.embedding = $embedding
                    MERGE (a)-[:HAS_PARAGRAPH]->(p)
                    """,
                    parent_article=paragraph.parent_clause,
                    paragraph_id=paragraph.paragraph_id,
                    number=paragraph.number,
                    text=paragraph.text,
                    embedding=paragraph.embedding if hasattr(paragraph, 'embedding') else None
                )
                stats['nodes_created'] += 1
            
            logger.info(f"  âœ… {len(all_paragraphs)}ê°œ í•­ ë¡œë”© ì™„ë£Œ")
            
            # Create items (í˜¸)
            logger.info(f"  í˜¸(è™Ÿ) ë¡œë”©: {len(all_items)}ê°œ")
            for i, item in enumerate(all_items, 1):
                try:
                    logger.debug(f"    [{i}/{len(all_items)}] {item.item_id} -> {item.parent_paragraph}")
                    session.run("""
                        MATCH (p:Paragraph {paragraphId: $parent_paragraph})
                        MERGE (i:Item {itemId: $item_id})
                        SET i.number = $number,
                            i.text = $text,
                            i.embedding = $embedding
                        MERGE (p)-[:HAS_ITEM]->(i)
                        """,
                        parent_paragraph=item.parent_paragraph,
                        item_id=item.item_id,
                        number=item.number,
                        text=item.text,
                        embedding=item.embedding if hasattr(item, 'embedding') else None
                    )
                    stats['nodes_created'] += 1
                except Exception as e:
                    logger.error(f"  âœ— í˜¸ {item.item_id} ì €ì¥ ì‹¤íŒ¨: {e}")
            
            logger.info(f"  âœ… {len(all_items)}ê°œ í˜¸ ë¡œë”© ì™„ë£Œ")
            
            # Create cross-references (Paragraph/Item â†’ Article/Paragraph/Item)
            logger.info(f"  ìƒí˜¸ ì°¸ì¡° ê´€ê³„ ìƒì„±: {len(all_references)}ê°œ")
            refs_created = 0
            
            for ref in all_references:
                try:
                    # Determine from_node label and property
                    if ref['from_type'] == 'paragraph':
                        from_label = 'Paragraph'
                        from_prop = 'paragraphId'
                    elif ref['from_type'] == 'item':
                        from_label = 'Item'
                        from_prop = 'itemId'
                    else:
                        continue
                    
                    # Determine to_node label and property
                    if ref['to_type'] == 'clause':
                        to_label = 'Article'
                        to_prop = 'articleId'
                    elif ref['to_type'] == 'paragraph':
                        to_label = 'Paragraph'
                        to_prop = 'paragraphId'
                    elif ref['to_type'] == 'item':
                        to_label = 'Item'
                        to_prop = 'itemId'
                    else:
                        continue
                    
                    # Create REFERS_TO relationship
                    query = f"""
                        MATCH (from_node:{from_label} {{{from_prop}: $from_id}})
                        MATCH (to_node:{to_label} {{{to_prop}: $to_id}})
                        MERGE (from_node)-[:REFERS_TO]->(to_node)
                    """
                    
                    session.run(query, from_id=ref['from_id'], to_id=ref['to_id'])
                    refs_created += 1
                    logger.debug(f"    ì°¸ì¡°: {ref['from_id']} â†’ {ref['to_id']}")
                    
                except Exception as e:
                    logger.warning(f"  âœ— ì°¸ì¡° ê´€ê³„ ìƒì„± ì‹¤íŒ¨ ({ref['from_id']} -> {ref['to_id']}): {e}")
            
            logger.info(f"  âœ… {refs_created}ê°œ ìƒí˜¸ ì°¸ì¡° ê´€ê³„ ìƒì„± ì™„ë£Œ")
        
        # Summary
        logger.info("\n" + "="*80)
        logger.info("âœ… ê³„ì¸µì  Ingestion ì™„ë£Œ!")
        logger.info("="*80)
        logger.info(f"PDF íŒŒì¼: {stats['pdf_file']}")
        logger.info(f"í˜ì´ì§€: {stats['pages']}ê°œ")
        logger.info(f"ì´ ì¡°í•­: {stats['total_clauses']}ê°œ")
        logger.info(f"ì²˜ë¦¬ëœ ì¡°í•­: {stats['processed_clauses']}ê°œ")
        logger.info(f"í•­(é …): {stats['paragraphs']}ê°œ")
        logger.info(f"í˜¸(è™Ÿ): {stats['items']}ê°œ")
        logger.info(f"ìƒí˜¸ ì°¸ì¡°: {stats['cross_references']}ê°œ")
        logger.info(f"ì„ë² ë”©: {stats['embeddings']}ê°œ")
        logger.info(f"ë…¸ë“œ ìƒì„±: {stats['nodes_created']}ê°œ")
        logger.info("="*80)
        
    except Exception as e:
        logger.error(f"âŒ Ingestion ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    finally:
        driver.close()


if __name__ == "__main__":
    main()

