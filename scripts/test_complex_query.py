#!/usr/bin/env python3
"""
Test Complex Query with Context Display
"""
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent))

from neo4j import GraphDatabase
from loguru import logger

from src.config.settings import settings
from src.retrieval.hierarchical_retriever import HierarchicalRetriever
from openai import OpenAI


def main():
    query = "ì„œë©´ë™ì˜ ì—†ì´ ê°€ì…ëœ ì‚¬ë§ë³´í—˜ì—ì„œ ë³´í—˜íšŒì‚¬ê°€ ë³´í—˜ë£Œë¥¼ ëŒë ¤ì£¼ì§€ ì•Šê³ , ê³„ì•½ìê°€ ì œ6ì¡°ì— ë”°ë¼ í•´ì§€ë¥¼ ì‹ ì²­í•˜ë©´ ì–´ë–»ê²Œ ì²˜ë¦¬ë˜ë‚˜?"
    
    print('='*80)
    print('ğŸ§ª ë³µì¡ ì§ˆì˜ í…ŒìŠ¤íŠ¸')
    print('='*80)
    print(f"ì§ˆì˜: {query}")
    print()
    
    # Connect to Neo4j
    driver = GraphDatabase.driver(
        settings.neo4j_uri,
        auth=(settings.neo4j_username, settings.neo4j_password)
    )
    
    # Initialize retriever
    retriever = HierarchicalRetriever(driver)
    
    # Retrieve context
    result = retriever.retrieve(query, top_k=5)
    
    if result['selected_article']:
        print('='*80)
        print('âœ… ì„ íƒëœ ì¡°í•­')
        print('='*80)
        print(f"ì¡°í•­ ID: {result['selected_article']['articleId']}")
        print(f"ì¡°í•­ ì œëª©: {result['selected_article']['title']}")
        print()
        
        print('='*80)
        print('ğŸ“Š ë©”íƒ€ë°ì´í„°')
        print('='*80)
        print(f"í›„ë³´ ë…¸ë“œ ìˆ˜: {result['metadata']['candidates_count']}")
        print(f"ìƒìœ„ ì¡°í•­ ìˆ˜: {result['metadata']['articles_count']}")
        print(f"ì°¸ì¡° ìˆ˜: {result['metadata']['references_count']}")
        print()
        
        print('='*80)
        print('ğŸ“ í¬í•¨ëœ ì†ŒìŠ¤')
        print('='*80)
        for i, source in enumerate(result['sources'], 1):
            print(f"{i}. {source['type']}: {source['id']}")
            if source.get('title'):
                print(f"   ì œëª©: {source['title']}")
        print()
        
        print('='*80)
        print('ğŸ”— ì°¸ì¡°ëœ ì¡°í•­ (REFERS_TO)')
        print('='*80)
        # Get references from context_data (not from result directly)
        refs_count = result['metadata'].get('references_count', 0)
        if refs_count > 0:
            print(f"ì´ {refs_count}ê°œì˜ ì°¸ì¡° ë°œê²¬")
            # References are embedded in the context itself
            print("(ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨ë¨)")
        else:
            print("ì°¸ì¡° ì—†ìŒ")
        print()
        
        print('='*80)
        print('ğŸ“„ LLMì—ê²Œ ì „ë‹¬ë˜ëŠ” ì „ì²´ ì»¨í…ìŠ¤íŠ¸')
        print('='*80)
        print(result['context'])
        print()
        print('='*80)
        
        # Generate answer using OpenAI
        print()
        print('='*80)
        print('ğŸ’¬ ìƒì„±ëœ ë‹µë³€')
        print('='*80)
        
        openai_client = OpenAI(api_key=settings.openai_api_key)
        
        try:
            response = openai_client.chat.completions.create(
                model=settings.llm_model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë³´í—˜ì•½ê´€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì•½ê´€ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": f"ì•½ê´€ ë‚´ìš©:\n\n{result['context']}\n\nì§ˆë¬¸: {query}\n\në‹µë³€:"}
                ],
                temperature=0.3,
                max_tokens=800
            )
            
            answer = response.choices[0].message.content
            print(answer)
            
        except Exception as e:
            logger.error(f"Answer generation failed: {e}")
    else:
        print("âŒ ê´€ë ¨ ì¡°í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    driver.close()


if __name__ == "__main__":
    main()

