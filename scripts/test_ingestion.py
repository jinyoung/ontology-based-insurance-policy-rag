#!/usr/bin/env python3
"""
Test ingestion with sample text (no PDF needed)
"""
import sys
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from loguru import logger
from neo4j import GraphDatabase
from openai import OpenAI

from src.config.settings import settings
from src.parsers.clause_extractor import ClauseExtractor
from src.chunking.semantic_chunker import SemanticChunker

# Sample policy text
SAMPLE_POLICY_TEXT = """
ã€ë„ë‚œìœ„í—˜ íŠ¹ë³„ì•½ê´€ã€‘

ì œ1ì¡°(ë³´ìƒí•˜ëŠ” ì†í•´) íšŒì‚¬ëŠ” ë³´í—˜ì¦ê¶Œì— ê¸°ì¬ëœ ë³´í—˜ì˜ ëª©ì ì— ëŒ€í•˜ì—¬ ë„ë‚œìœ¼ë¡œ ì¸í•œ ì†í•´ë¥¼ ë³´ìƒí•©ë‹ˆë‹¤.
â‘  ë„ë‚œìœ¼ë¡œ ì¸í•œ ì§ì ‘ì ì¸ ì†í•´ë¥¼ ë³´ìƒí•©ë‹ˆë‹¤.
â‘¡ ë„ë‚œë¬¼í’ˆì˜ íšŒìˆ˜ì— ì†Œìš”ëœ ë¹„ìš©ì„ ë³´ìƒí•©ë‹ˆë‹¤.

ì œ2ì¡°(ë³´ìƒí•˜ì§€ ì•„ë‹ˆí•˜ëŠ” ì†í•´) íšŒì‚¬ëŠ” ë‹¤ìŒì˜ ì†í•´ëŠ” ë³´ìƒí•˜ì§€ ì•„ë‹ˆí•©ë‹ˆë‹¤.
1. ê³„ì•½ì, í”¼ë³´í—˜ì ë˜ëŠ” ì´ë“¤ì˜ ë²•ì •ëŒ€ë¦¬ì¸ì˜ ê³ ì˜ ë˜ëŠ” ì¤‘ëŒ€í•œ ê³¼ì‹¤ë¡œ ìƒê¸´ ì†í•´
2. ì „ìŸ, í˜ëª…, ë‚´ë€, ì‚¬ë³€, í­ë™, ì†Œìš” ë° ì´ì™€ ìœ ì‚¬í•œ ì‚¬íƒœë¡œ ìƒê¸´ ì†í•´
3. ì§€ì§„, ë¶„í™” ë“± ì²œì¬ì§€ë³€ìœ¼ë¡œ ìƒê¸´ ì†í•´

ì œ3ì¡°(ìê¸°ë¶€ë‹´ê¸ˆ) íšŒì‚¬ê°€ ë³´ìƒí•  ì†í•´ì•¡ì—ì„œ ì¦ê¶Œì— ê¸°ì¬ëœ ìê¸°ë¶€ë‹´ê¸ˆì„ ê³µì œí•˜ê³  ë³´í—˜ê¸ˆì„ ì§€ê¸‰í•©ë‹ˆë‹¤.
"""

def main():
    print("\n" + "="*80)
    print("ğŸš€ í…ŒìŠ¤íŠ¸ ë°ì´í„° Ingestion ì‹œì‘")
    print("="*80)
    
    # Step 1: Extract clauses
    print("\n[Step 1] ì¡°í•­ ì¶”ì¶œ...")
    extractor = ClauseExtractor()
    clauses = extractor.extract_clauses(SAMPLE_POLICY_TEXT)
    
    for clause in clauses:
        extractor.extract_items_from_clause(clause)
    
    print(f"âœ… {len(clauses)}ê°œ ì¡°í•­ ì¶”ì¶œ ì™„ë£Œ")
    
    # Step 2: Semantic chunking
    print("\n[Step 2] ì‹œë§¨í‹± ì²­í‚¹...")
    chunker = SemanticChunker()
    all_chunks = []
    
    for clause in clauses:
        if len(clause.full_text) > 150:
            metadata = {
                'clause_id': clause.clause_id,
                'title': clause.title,
                'clause_type': clause.clause_type
            }
            chunks = chunker.chunk_text(clause.full_text, metadata)
            all_chunks.extend(chunks)
            print(f"  {clause.clause_id}: {len(chunks)}ê°œ ì²­í¬")
        else:
            print(f"  {clause.clause_id}: í…ìŠ¤íŠ¸ê°€ ì§§ì•„ ê±´ë„ˆëœ€")
    
    print(f"âœ… ì´ {len(all_chunks)}ê°œ ì²­í¬ ìƒì„±")
    
    # Step 3: Generate embeddings
    print("\n[Step 3] ì„ë² ë”© ìƒì„±...")
    openai_client = OpenAI(api_key=settings.openai_api_key)
    
    chunks_with_embeddings = []
    for chunk in all_chunks:
        try:
            response = openai_client.embeddings.create(
                model=settings.embedding_model,
                input=chunk.content
            )
            embedding = response.data[0].embedding
            
            chunks_with_embeddings.append({
                'chunk_id': chunk.chunk_id,
                'text': chunk.content,
                'embedding': embedding,
                'semantic_type': chunk.semantic_type,
                'metadata': chunk.metadata
            })
        except Exception as e:
            logger.warning(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            continue
    
    print(f"âœ… {len(chunks_with_embeddings)}ê°œ ì„ë² ë”© ìƒì„± ì™„ë£Œ")
    
    # Step 4: Load into Neo4j
    print("\n[Step 4] Neo4jì— ë¡œë”©...")
    driver = GraphDatabase.driver(
        settings.neo4j_uri,
        auth=(settings.neo4j_username, settings.neo4j_password)
    )
    
    with driver.session() as session:
        # Create product and version
        session.run("""
            MERGE (prod:InsuranceProduct {code: 'TEST_THEFT_2025'})
            SET prod.name = 'í…ŒìŠ¤íŠ¸ ë„ë‚œë³´í—˜',
                prod.kind = 'property'
            """)
        
        session.run("""
            MATCH (prod:InsuranceProduct {code: 'TEST_THEFT_2025'})
            MERGE (ver:PolicyVersion {versionId: 'TEST_THEFT_2025_V1'})
            SET ver.effectiveFrom = date()
            MERGE (prod)-[:HAS_POLICY_VERSION]->(ver)
            """)
        
        # Create clauses
        for clause in clauses:
            session.run("""
                MATCH (ver:PolicyVersion {versionId: 'TEST_THEFT_2025_V1'})
                MERGE (c:PolicyClause {clauseId: $clause_id})
                SET c.title = $title,
                    c.clauseType = $clause_type,
                    c.text = $text,
                    c.sectionPath = $section_path,
                    c.articleNumber = $article_number
                MERGE (ver)-[:HAS_CLAUSE]->(c)
                """,
                clause_id=clause.clause_id,
                title=clause.title,
                clause_type=clause.clause_type or 'General',
                text=clause.full_text,
                section_path=clause.section_path,
                article_number=clause.article_number
            )
            
            # Create special clause link
            if clause.parent_section:
                session.run("""
                    MATCH (ver:PolicyVersion {versionId: 'TEST_THEFT_2025_V1'})
                    MATCH (c:PolicyClause {clauseId: $clause_id})
                    MERGE (sc:SpecialClause {name: $special_clause_name})
                    MERGE (ver)-[:HAS_SPECIAL_CLAUSE]->(sc)
                    MERGE (sc)-[:HAS_CLAUSE]->(c)
                    """,
                    clause_id=clause.clause_id,
                    special_clause_name=clause.parent_section
                )
        
        print(f"  âœ… {len(clauses)}ê°œ ì¡°í•­ ë¡œë”© ì™„ë£Œ")
        
        # Create chunks with embeddings
        for chunk_data in chunks_with_embeddings:
            parent_clause_id = chunk_data['metadata'].get('clause_id')
            
            session.run("""
                MATCH (c:PolicyClause {clauseId: $parent_clause_id})
                CREATE (p:ParagraphChunk {
                    chunkId: $chunk_id,
                    text: $text,
                    semanticType: $semantic_type,
                    embedding: $embedding
                })
                CREATE (c)-[:HAS_PARAGRAPH]->(p)
                """,
                parent_clause_id=parent_clause_id,
                chunk_id=chunk_data['chunk_id'],
                text=chunk_data['text'],
                semantic_type=chunk_data['semantic_type'],
                embedding=chunk_data['embedding']  # ì„ë² ë”© ì¶”ê°€!
            )
            
            # Create Coverage/Exclusion nodes
            if chunk_data['semantic_type'] == 'coverage':
                session.run("""
                    MATCH (p:ParagraphChunk {chunkId: $chunk_id})
                    MERGE (cov:Coverage {
                        code: $code,
                        name: $name
                    })
                    MERGE (p)-[:DEFINES_COVERAGE]->(cov)
                    """,
                    chunk_id=chunk_data['chunk_id'],
                    code=f"COV_{chunk_data['chunk_id']}",
                    name=chunk_data['text'][:50]
                )
            elif chunk_data['semantic_type'] == 'exclusion':
                session.run("""
                    MATCH (p:ParagraphChunk {chunkId: $chunk_id})
                    MERGE (exc:Exclusion {
                        code: $code,
                        description: $description
                    })
                    MERGE (p)-[:HAS_EXCLUSION]->(exc)
                    """,
                    chunk_id=chunk_data['chunk_id'],
                    code=f"EXC_{chunk_data['chunk_id']}",
                    description=chunk_data['text'][:50]
                )
        
        print(f"  âœ… {len(chunks_with_embeddings)}ê°œ ì²­í¬ ë¡œë”© ì™„ë£Œ")
        
        # Verify
        result = session.run("""
            MATCH (ver:PolicyVersion {versionId: 'TEST_THEFT_2025_V1'})
            OPTIONAL MATCH (ver)-[:HAS_CLAUSE]->(c:PolicyClause)
            OPTIONAL MATCH (c)-[:HAS_PARAGRAPH]->(p:ParagraphChunk)
            RETURN count(DISTINCT c) as clauses, count(DISTINCT p) as chunks
            """)
        
        record = result.single()
        print(f"\nâœ… ê²€ì¦ ì™„ë£Œ:")
        print(f"   - ì¡°í•­: {record['clauses']}ê°œ")
        print(f"   - ì²­í¬: {record['chunks']}ê°œ")
    
    driver.close()
    
    print("\n" + "="*80)
    print("âœ… Ingestion ì™„ë£Œ!")
    print("="*80)
    print("\nğŸ’¡ ë‹¤ìŒ: python3 scripts/test_qa_simple.py ë¡œ QA í…ŒìŠ¤íŠ¸")


if __name__ == "__main__":
    main()

