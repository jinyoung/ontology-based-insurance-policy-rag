#!/usr/bin/env python3
"""
Test Hierarchical Retrieval Strategy

Tests the new retrieval logic:
1. Vector search for top-k nodes
2. Get parent Articles
3. LLM selects best Article
4. Build context with REFERS_TO connections
"""
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent))

from neo4j import GraphDatabase
from loguru import logger
from openai import OpenAI

from src.config.settings import settings
from src.retrieval.hierarchical_retriever import HierarchicalRetriever


def main():
    logger.info("="*80)
    logger.info("ğŸ”¬ Hierarchical Retrieval Test")
    logger.info("="*80)
    
    # Connect to Neo4j
    driver = GraphDatabase.driver(
        settings.neo4j_uri,
        auth=(settings.neo4j_username, settings.neo4j_password)
    )
    
    # Initialize retriever
    retriever = HierarchicalRetriever(driver)
    
    # Test queries
    test_queries = [
        "ì²­ì•½ì„ ì² íšŒí•  ìˆ˜ ìˆë‚˜ìš”?",
        "ê³„ì•½ì´ ë¬´íš¨ê°€ ë˜ëŠ” ê²½ìš°ëŠ”?",
        "ë³´í—˜ë£ŒëŠ” ì–´ë–»ê²Œ ë‚©ì…í•˜ë‚˜ìš”?",
    ]
    
    openai_client = OpenAI(api_key=settings.openai_api_key)
    
    for i, query in enumerate(test_queries, 1):
        logger.info(f"\n{'='*80}")
        logger.info(f"[Test {i}/{len(test_queries)}] Query: {query}")
        logger.info(f"{'='*80}\n")
        
        # Retrieve context
        result = retriever.retrieve(query, top_k=5)
        
        if result['selected_article']:
            print("âœ… ì„ íƒëœ ì¡°í•­:")
            print(f"   {result['selected_article']['articleId']}: {result['selected_article']['title']}")
            print()
            
            print("ğŸ“Š ë©”íƒ€ë°ì´í„°:")
            for key, value in result['metadata'].items():
                print(f"   {key}: {value}")
            print()
            
            print("ğŸ“ ì°¸ì¡°ëœ ì¡°í•­:")
            if result['sources']:
                for source in result['sources']:
                    print(f"   - {source['type']}: {source['id']}")
            if result.get('metadata', {}).get('references_count', 0) > 0:
                for ref in result.get('metadata', {}).get('references', []):
                    print(f"   - [ì°¸ì¡°] {ref.get('type')}: {ref.get('id')}")
            print()
            
            print("ğŸ“„ ì»¨í…ìŠ¤íŠ¸ (ì²˜ìŒ 500ì):")
            print(result['context'][:500])
            print("...")
            print()
            
            # Generate answer using LLM
            print("ğŸ’¬ ìƒì„±ëœ ë‹µë³€:")
            try:
                response = openai_client.chat.completions.create(
                    model=settings.llm_model,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ë³´í—˜ì•½ê´€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì•½ê´€ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."},
                        {"role": "user", "content": f"ì•½ê´€ ë‚´ìš©:\n\n{result['context']}\n\nì§ˆë¬¸: {query}\n\në‹µë³€:"}
                    ],
                    temperature=0.3,
                    max_tokens=500
                )
                
                answer = response.choices[0].message.content
                print(answer)
                
            except Exception as e:
                logger.error(f"Answer generation failed: {e}")
        else:
            print("âŒ ê´€ë ¨ ì¡°í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            if 'error' in result.get('metadata', {}):
                print(f"   ì˜¤ë¥˜: {result['metadata']['error']}")
        
        print()
    
    driver.close()
    logger.info("âœ… Test completed")


if __name__ == "__main__":
    main()

